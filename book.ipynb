{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f25dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# works for pure text wala pdf \n",
    "\n",
    "# import PyPDF2\n",
    "\n",
    "# pdfFileObj = open('/var/home/ramrshrcg/Downloads/Natural-language-processing-with-Transformers-_-building-Lewis-Tunstall-Leandro-von-Werra-Thomas-Wolf-Revised-edition-Sebastopol-CA-2022-9781098103170-0060a3b3e6eaec8c73a59ce5fe80bddf-Annas-Archiv.pdf', 'rb')\n",
    "\n",
    "# pdfReader = PyPDF2.PdfReader(pdfFileObj)\n",
    "\n",
    "# # num_pages = pdfReader.numPage\n",
    "# # s\n",
    "# num_pages = len(pdfReader.pages)\n",
    "\n",
    "# text = \"\"\n",
    "\n",
    "# # for i in range(num_pages):\n",
    "    \n",
    "#     # pageObj = pdfReader.pages[i]\n",
    "#     # text += pageObj.extract_text()\n",
    "\n",
    "# # print(text)\n",
    "\n",
    "# pageObj = pdfReader.pages[2]\n",
    "# text += pageObj.extract_text()\n",
    "# print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5bbfe3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just remove the --user flag\n",
    "%pip install pdfplumber pytesseract pdf2image Pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a03e127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import PyPDF2\n",
    "# import pdfplumber\n",
    "# import pytesseract\n",
    "# from pdf2image import convert_from_path\n",
    "# from PIL import Image\n",
    "# import os\n",
    "# import gc\n",
    "# import sys\n",
    "# import re\n",
    "\n",
    "# class MemoryOptimizedPDFExtractor:\n",
    "#     def clean_nepali_text(self, text):\n",
    "#         \"\"\"\n",
    "#         Remove all English letters, numbers, and keep only Nepali/Devanagari text\n",
    "#         \"\"\"\n",
    "#         if not text:\n",
    "#             return \"\"\n",
    "        \n",
    "#         # Remove English letters (a-z, A-Z) and numbers (0-9)\n",
    "#         # Keep Devanagari characters (0x0900-0x097F), whitespace, and common punctuation\n",
    "#         cleaned_lines = []\n",
    "        \n",
    "#         for line in text.split('\\n'):\n",
    "#             # Remove English letters and numbers\n",
    "#             cleaned_line = re.sub(r'[a-zA-Z0-9]', '', line)\n",
    "            \n",
    "#             # Remove extra whitespace\n",
    "#             cleaned_line = ' '.join(cleaned_line.split())\n",
    "            \n",
    "#             # Only keep lines that have meaningful content after cleaning\n",
    "#             if cleaned_line.strip():\n",
    "#                 cleaned_lines.append(cleaned_line)\n",
    "        \n",
    "#         return '\\n'.join(cleaned_lines)\n",
    "    \n",
    "#     def format_page_separator(self, page_number):\n",
    "#         \"\"\"Create page separator in Nepali numerals\"\"\"\n",
    "#         # Convert to Nepali numerals\n",
    "#         nepali_numerals = {'0': '‡•¶', '1': '‡•ß', '2': '‡•®', '3': '‡•©', '4': '‡•™', \n",
    "#                           '5': '‡•´', '6': '‡•¨', '7': '‡•≠', '8': '‡•Æ', '9': '‡•Ø'}\n",
    "        \n",
    "#         page_str = str(page_number)\n",
    "#         nepali_page_num = ''.join(nepali_numerals.get(digit, digit) for digit in page_str)\n",
    "        \n",
    "#         return f\"\\n--- ‡§™‡•É‡§∑‡•ç‡§† {nepali_page_num} ---\\n\"\n",
    "#     def __init__(self, max_pages_batch=5, dpi=200):\n",
    "#         \"\"\"\n",
    "#         Memory-optimized PDF text extractor\n",
    "        \n",
    "#         Args:\n",
    "#             max_pages_batch: Process this many pages at once (lower = less memory)\n",
    "#             dpi: Image resolution (lower = less memory, but worse OCR quality)\n",
    "#         \"\"\"\n",
    "#         self.max_pages_batch = max_pages_batch\n",
    "#         self.dpi = dpi\n",
    "        \n",
    "#     def extract_text_lightweight(self, pdf_path):\n",
    "#         \"\"\"Lightweight text extraction - tries pdfplumber first\"\"\"\n",
    "#         try:\n",
    "#             text = \"\"\n",
    "#             with pdfplumber.open(pdf_path) as pdf:\n",
    "#                 total_pages = len(pdf.pages)\n",
    "#                 print(f\"Processing {total_pages} pages...\")\n",
    "                \n",
    "#                 for page_num, page in enumerate(pdf.pages):\n",
    "#                     print(f\"\\r‡§™‡•É‡§∑‡•ç‡§† {page_num + 1}/{total_pages}\", end=\"\", flush=True)\n",
    "                    \n",
    "#                     page_text = page.extract_text()\n",
    "#                     if page_text:\n",
    "#                         # Clean the text to remove English and numbers\n",
    "#                         cleaned_text = self.clean_nepali_text(page_text)\n",
    "#                         if cleaned_text.strip():  # Only add if there's content after cleaning\n",
    "#                             text += self.format_page_separator(page_num + 1) + cleaned_text\n",
    "                    \n",
    "#                     # Clear memory every few pages\n",
    "#                     if (page_num + 1) % 10 == 0:\n",
    "#                         gc.collect()\n",
    "                \n",
    "#                 print()  # New line after progress\n",
    "#                 return text\n",
    "                \n",
    "#         except Exception as e:\n",
    "#             print(f\"Error with text extraction: {e}\")\n",
    "#             return None\n",
    "    \n",
    "#     def extract_with_batched_ocr(self, pdf_path, output_file=None, language='nep'):\n",
    "#         \"\"\"\n",
    "#         Memory-efficient OCR - processes pages in small batches\n",
    "#         Optionally saves directly to file to avoid keeping everything in memory\n",
    "#         \"\"\"\n",
    "#         try:\n",
    "#             # Get total page count first\n",
    "#             from pdf2image.exceptions import PDFInfoNotInstalledError\n",
    "            \n",
    "#             print(\"Analyzing PDF...\")\n",
    "#             total_pages = self._get_page_count(pdf_path)\n",
    "#             print(f\"Total pages: {total_pages}\")\n",
    "            \n",
    "#             # Open output file if specified\n",
    "#             output_handle = None\n",
    "#             if output_file:\n",
    "#                 output_handle = open(output_file, 'w', encoding='utf-8')\n",
    "#                 print(f\"‡§´‡§æ‡§á‡§≤‡§Æ‡§æ ‡§∏‡•á‡§≠ ‡§ó‡§∞‡•ç‡§¶‡•à: {output_file}\")\n",
    "            \n",
    "#             all_text = \"\"\n",
    "            \n",
    "#             # Process in batches\n",
    "#             for start_page in range(0, total_pages, self.max_pages_batch):\n",
    "#                 end_page = min(start_page + self.max_pages_batch, total_pages)\n",
    "#                 print(f\"\\n‡§™‡•É‡§∑‡•ç‡§† {start_page + 1}-{end_page} ‡§™‡•ç‡§∞‡§ï‡•ç‡§∞‡§ø‡§Ø‡§æ ‡§ó‡§∞‡•ç‡§¶‡•à...\")\n",
    "                \n",
    "#                 # Convert only current batch to images\n",
    "#                 images = convert_from_path(\n",
    "#                     pdf_path,\n",
    "#                     dpi=self.dpi,\n",
    "#                     first_page=start_page + 1,\n",
    "#                     last_page=end_page\n",
    "#                 )\n",
    "                \n",
    "#                 # Process each image in the batch\n",
    "#                 for i, image in enumerate(images):\n",
    "#                     current_page = start_page + i + 1\n",
    "#                     print(f\"  ‡§™‡•É‡§∑‡•ç‡§† {current_page} OCR...\")\n",
    "                    \n",
    "#                     # Extract text from current page\n",
    "#                     try:\n",
    "#                         page_text = pytesseract.image_to_string(\n",
    "#                             image, \n",
    "#                             lang=language,\n",
    "#                             config='--psm 6'\n",
    "#                         )\n",
    "                        \n",
    "#                         # Clean the extracted text\n",
    "#                         cleaned_text = self.clean_nepali_text(page_text)\n",
    "                        \n",
    "#                         if cleaned_text.strip():  # Only add if there's meaningful content\n",
    "#                             formatted_text = self.format_page_separator(current_page) + cleaned_text\n",
    "                            \n",
    "#                             if output_handle:\n",
    "#                                 # Write directly to file\n",
    "#                                 output_handle.write(formatted_text)\n",
    "#                                 output_handle.flush()\n",
    "#                             else:\n",
    "#                                 all_text += formatted_text\n",
    "                            \n",
    "#                     except Exception as e:\n",
    "#                         print(f\"‡§™‡•É‡§∑‡•ç‡§† {current_page} ‡§§‡•ç‡§∞‡•Å‡§ü‡§ø: {e}\")\n",
    "                    \n",
    "#                     # Clear individual image from memory\n",
    "#                     del image\n",
    "                \n",
    "#                 # Clear batch from memory\n",
    "#                 del images\n",
    "#                 gc.collect()\n",
    "                \n",
    "#                 print(f\"  ‡§™‡•Ç‡§∞‡•ç‡§£ ‡§≠‡§Ø‡•ã‡•§ ‡§Æ‡•á‡§Æ‡•ã‡§∞‡•Ä ‡§ñ‡§æ‡§≤‡•Ä ‡§ó‡§∞‡§ø‡§Ø‡•ã‡•§\")\n",
    "            \n",
    "#             # Close output file if used\n",
    "#             if output_handle:\n",
    "#                 output_handle.close()\n",
    "#                 print(f\"\\n‡§ü‡•á‡§ï‡•ç‡§∏‡•ç‡§ü ‡§∏‡•á‡§≠ ‡§≠‡§Ø‡•ã: {output_file}\")\n",
    "#                 return f\"‡§ü‡•á‡§ï‡•ç‡§∏‡•ç‡§ü ‡§∏‡•á‡§≠ ‡§≠‡§Ø‡•ã {output_file}\"\n",
    "#             else:\n",
    "#                 return all_text\n",
    "                \n",
    "#         except Exception as e:\n",
    "#             print(f\"Error with batched OCR: {e}\")\n",
    "#             if output_handle:\n",
    "#                 output_handle.close()\n",
    "#             return None\n",
    "    \n",
    "#     def _get_page_count(self, pdf_path):\n",
    "#         \"\"\"Get total page count without loading entire PDF\"\"\"\n",
    "#         try:\n",
    "#             with pdfplumber.open(pdf_path) as pdf:\n",
    "#                 return len(pdf.pages)\n",
    "#         except:\n",
    "#             # Fallback method\n",
    "#             try:\n",
    "#                 with open(pdf_path, 'rb') as file:\n",
    "#                     pdf_reader = PyPDF2.PdfReader(file)\n",
    "#                     return len(pdf_reader.pages)\n",
    "#             except:\n",
    "#                 return 1  # Assume 1 page if can't determine\n",
    "    \n",
    "#     def extract_single_page(self, pdf_path, page_number, language='nep'):\n",
    "#         \"\"\"Extract text from a single page (for testing)\"\"\"\n",
    "#         try:\n",
    "#             print(f\"‡§™‡•É‡§∑‡•ç‡§† {page_number} ‡§®‡§ø‡§ï‡§æ‡§≤‡•ç‡§¶‡•à...\")\n",
    "            \n",
    "#             # Convert single page to image\n",
    "#             images = convert_from_path(\n",
    "#                 pdf_path,\n",
    "#                 dpi=self.dpi,\n",
    "#                 first_page=page_number,\n",
    "#                 last_page=page_number\n",
    "#             )\n",
    "            \n",
    "#             if images:\n",
    "#                 image = images[0]\n",
    "#                 text = pytesseract.image_to_string(image, lang=language, config='--psm 6')\n",
    "                \n",
    "#                 # Clean the text\n",
    "#                 cleaned_text = self.clean_nepali_text(text)\n",
    "                \n",
    "#                 # Clean up\n",
    "#                 del images\n",
    "#                 del image\n",
    "#                 gc.collect()\n",
    "                \n",
    "#                 return cleaned_text\n",
    "            \n",
    "#         except Exception as e:\n",
    "#             print(f\"‡§è‡§â‡§ü‡•à ‡§™‡•É‡§∑‡•ç‡§† ‡§®‡§ø‡§ï‡§æ‡§≤‡•ç‡§® ‡§§‡•ç‡§∞‡•Å‡§ü‡§ø: {e}\")\n",
    "#             return None\n",
    "    \n",
    "#     def smart_extract(self, pdf_path, output_file=None, language='nep'):\n",
    "#         \"\"\"\n",
    "#         Smart extraction: tries text extraction first, falls back to OCR\n",
    "#         Saves directly to file to minimize memory usage\n",
    "#         \"\"\"\n",
    "#         print(\"=== ‡§®‡•á‡§™‡§æ‡§≤‡•Ä PDF ‡§ü‡•á‡§ï‡•ç‡§∏‡•ç‡§ü ‡§®‡§ø‡§ï‡§æ‡§≤‡•ç‡§®‡•á ===\")\n",
    "#         print(f\"‡§á‡§®‡§™‡•Å‡§ü: {pdf_path}\")\n",
    "        \n",
    "#         # First, try regular text extraction\n",
    "#         print(\"\\n‡•ß. ‡§∏‡§æ‡§Æ‡§æ‡§®‡•ç‡§Ø ‡§ü‡•á‡§ï‡•ç‡§∏‡•ç‡§ü ‡§®‡§ø‡§ï‡§æ‡§≤‡•ç‡§®‡•á ‡§™‡•ç‡§∞‡§Ø‡§æ‡§∏...\")\n",
    "#         text = self.extract_text_lightweight(pdf_path)\n",
    "        \n",
    "#         if text and self._contains_meaningful_text(text):\n",
    "#             print(\"‚úì ‡§∏‡§æ‡§Æ‡§æ‡§®‡•ç‡§Ø ‡§®‡§ø‡§ï‡§æ‡§∏‡•Ä‡§Æ‡§æ ‡§Ö‡§∞‡•ç‡§•‡§™‡•Ç‡§∞‡•ç‡§£ ‡§ü‡•á‡§ï‡•ç‡§∏‡•ç‡§ü ‡§≠‡•á‡§ü‡§ø‡§Ø‡•ã!\")\n",
    "            \n",
    "#             if output_file:\n",
    "#                 with open(output_file, 'w', encoding='utf-8') as f:\n",
    "#                     f.write(text)\n",
    "#                 print(f\"‚úì ‡§ü‡•á‡§ï‡•ç‡§∏‡•ç‡§ü ‡§∏‡•á‡§≠ ‡§≠‡§Ø‡•ã: {output_file}\")\n",
    "#                 return f\"‡§ü‡•á‡§ï‡•ç‡§∏‡•ç‡§ü ‡§∏‡•á‡§≠ ‡§≠‡§Ø‡•ã {output_file}\"\n",
    "#             else:\n",
    "#                 return text\n",
    "        \n",
    "#         # If regular extraction didn't work, use OCR\n",
    "#         print(\"\\n‡•®. ‡§∏‡§æ‡§Æ‡§æ‡§®‡•ç‡§Ø ‡§®‡§ø‡§ï‡§æ‡§∏‡•Ä ‡§∞‡§æ‡§Æ‡•ç‡§∞‡•ã ‡§≠‡§è‡§®‡•§ OCR ‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó ‡§ó‡§∞‡•ç‡§¶‡•à...\")\n",
    "#         return self.extract_with_batched_ocr(pdf_path, output_file, language)\n",
    "    \n",
    "#     def _contains_meaningful_text(self, text):\n",
    "#         \"\"\"Check if extracted text is meaningful\"\"\"\n",
    "#         if not text:\n",
    "#             return False\n",
    "        \n",
    "#         # Remove whitespace and count actual characters\n",
    "#         clean_text = ''.join(text.split())\n",
    "        \n",
    "#         # Check for minimum length and variety\n",
    "#         if len(clean_text) < 50:\n",
    "#             return False\n",
    "        \n",
    "#         # Check for Nepali characters (Devanagari)\n",
    "#         nepali_chars = sum(1 for char in clean_text if 0x0900 <= ord(char) <= 0x097F)\n",
    "        \n",
    "#         # If we have Nepali characters or substantial English text\n",
    "#         return nepali_chars > 10 or len(clean_text) > 200\n",
    "\n",
    "\n",
    "# # Simple wrapper functions for easy use\n",
    "# def extract_nepali_pdf_memory_safe(pdf_path, output_file=None, batch_size=3, dpi=200):\n",
    "#     \"\"\"\n",
    "#     Memory-safe Nepali PDF extraction - removes all English text and numbers\n",
    "    \n",
    "#     Args:\n",
    "#         pdf_path: Path to PDF file\n",
    "#         output_file: Save to file instead of returning text (recommended for large PDFs)\n",
    "#         batch_size: Pages to process at once (lower = less memory)\n",
    "#         dpi: Image resolution (lower = less memory)\n",
    "#     \"\"\"\n",
    "#     extractor = MemoryOptimizedPDFExtractor(max_pages_batch=batch_size, dpi=dpi)\n",
    "#     return extractor.smart_extract(pdf_path, output_file, language='nep')\n",
    "\n",
    "\n",
    "# def test_single_page_clean(pdf_path, page_num=1):\n",
    "#     \"\"\"Test extraction on a single page first - only Nepali text\"\"\"\n",
    "#     extractor = MemoryOptimizedPDFExtractor(dpi=200)\n",
    "#     return extractor.extract_single_page(pdf_path, page_num, language='nep')\n",
    "\n",
    "\n",
    "# # Example usage\n",
    "# if __name__ == \"__main__\":\n",
    "#     # Configuration for low memory usage\n",
    "#     PDF_PATH =  'Nepali Materials/‡§Ö‡§∞‡•ç‡§•‡§§‡§®‡•ç‡§§‡•ç‡§∞‡§Æ‡§æ ‡§ï‡•ã‡§∞‡•ã‡§®‡§æ ‡§ï‡§π‡§∞.pdf'\n",
    "    \n",
    "#     filename = os.path.basename(PDF_PATH)\n",
    "    \n",
    "#     OUTPUT_FILE = f\"Books/{filename}.csv\"  # Output file\n",
    "    \n",
    "    \n",
    "#     if not os.path.exists(PDF_PATH):\n",
    "#         print(\"‡§ï‡•É‡§™‡§Ø‡§æ PDF_PATH ‡§≤‡§æ‡§à ‡§Ü‡§´‡•ç‡§®‡•ã ‡§µ‡§æ‡§∏‡•ç‡§§‡§µ‡§ø‡§ï PDF ‡§´‡§æ‡§á‡§≤ ‡§™‡§æ‡§•‡§∏‡§Å‡§ó ‡§Ö‡§™‡§°‡•á‡§ü ‡§ó‡§∞‡•ç‡§®‡•Å‡§π‡•ã‡§∏‡•ç\")\n",
    "#         sys.exit(1)\n",
    "    \n",
    "#     print(\"‡§Æ‡•á‡§Æ‡•ã‡§∞‡•Ä-‡§Ö‡§®‡•Å‡§ï‡•Ç‡§≤‡§ø‡§§ ‡§®‡•á‡§™‡§æ‡§≤‡•Ä PDF ‡§®‡§ø‡§ï‡§æ‡§∏‡•Ä\")\n",
    "#     print(f\"‡§¨‡•ç‡§Ø‡§æ‡§ö ‡§∏‡§æ‡§á‡§ú: 3 ‡§™‡•É‡§∑‡•ç‡§†‡§π‡§∞‡•Ç (‡§ï‡§Æ ‡§Æ‡•á‡§Æ‡•ã‡§∞‡•Ä ‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó)\")\n",
    "#     print(f\"DPI: 200 (‡§ó‡•Å‡§£‡§∏‡•ç‡§§‡§∞ ‡§∞ ‡§Æ‡•á‡§Æ‡•ã‡§∞‡•Ä‡§ï‡•ã ‡§∏‡§®‡•ç‡§§‡•Å‡§≤‡§®)\")\n",
    "    \n",
    "#     # Test single page first\n",
    "#     print(\"\\n=== ‡§™‡§π‡§ø‡§≤‡•á ‡§è‡§â‡§ü‡•à ‡§™‡•É‡§∑‡•ç‡§† ‡§™‡§∞‡•Ä‡§ï‡•ç‡§∑‡§£ ===\")\n",
    "#     test_text = test_single_page_clean(PDF_PATH, 1)\n",
    "#     if test_text:\n",
    "#         print(\"‚úì ‡§è‡§â‡§ü‡•à ‡§™‡•É‡§∑‡•ç‡§† ‡§™‡§∞‡•Ä‡§ï‡•ç‡§∑‡§£ ‡§∏‡§´‡§≤!\")\n",
    "#         print(f\"‡§®‡§Æ‡•Ç‡§®‡§æ: {test_text[:200]}...\")\n",
    "        \n",
    "#         # Proceed with full extraction\n",
    "#         print(f\"\\n=== ‡§™‡•Ç‡§∞‡•ç‡§£ PDF ‡§™‡•ç‡§∞‡§ï‡•ç‡§∞‡§ø‡§Ø‡§æ ===\")\n",
    "#         result = extract_nepali_pdf_memory_safe(\n",
    "#             PDF_PATH, \n",
    "#             OUTPUT_FILE, \n",
    "#             batch_size=2,  # Very small batches\n",
    "#             dpi=200        # Lower resolution\n",
    "#         )\n",
    "#         print(f\"‡§™‡§∞‡§ø‡§£‡§æ‡§Æ: {result}\")\n",
    "#     else:\n",
    "#         print(\"‚úó ‡§è‡§â‡§ü‡•à ‡§™‡•É‡§∑‡•ç‡§† ‡§™‡§∞‡•Ä‡§ï‡•ç‡§∑‡§£ ‡§Ö‡§∏‡§´‡§≤\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2b69aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import PyPDF2\n",
    "# import pdfplumber\n",
    "# import pytesseract\n",
    "# from pdf2image import convert_from_path\n",
    "# from PIL import Image\n",
    "# import os\n",
    "# import gc\n",
    "# import sys\n",
    "# import re\n",
    "# import time\n",
    "# from pathlib import Path\n",
    "\n",
    "# class MemoryOptimizedPDFExtractor:\n",
    "#     def clean_nepali_text(self, text):\n",
    "#         \"\"\"\n",
    "#         Remove all English letters, numbers, and keep only Nepali/Devanagari text\n",
    "#         \"\"\"\n",
    "#         if not text:\n",
    "#             return \"\"\n",
    "        \n",
    "#         # Remove English letters (a-z, A-Z) and numbers (0-9)\n",
    "#         # Keep Devanagari characters (0x0900-0x097F), whitespace, and common punctuation\n",
    "#         cleaned_lines = []\n",
    "        \n",
    "#         for line in text.split('\\n'):\n",
    "#             # Remove English letters and numbers\n",
    "#             cleaned_line = re.sub(r'[a-zA-Z0-9]', '', line)\n",
    "            \n",
    "#             # Remove extra whitespace\n",
    "#             cleaned_line = ' '.join(cleaned_line.split())\n",
    "            \n",
    "#             # Only keep lines that have meaningful content after cleaning\n",
    "#             if cleaned_line.strip():\n",
    "#                 cleaned_lines.append(cleaned_line)\n",
    "        \n",
    "#         return '\\n'.join(cleaned_lines)\n",
    "    \n",
    "#     def format_page_separator(self, page_number):\n",
    "#         \"\"\"Create page separator in Nepali numerals\"\"\"\n",
    "#         # Convert to Nepali numerals\n",
    "#         nepali_numerals = {'0': '‡•¶', '1': '‡•ß', '2': '‡•®', '3': '‡•©', '4': '‡•™', \n",
    "#                           '5': '‡•´', '6': '‡•¨', '7': '‡•≠', '8': '‡•Æ', '9': '‡•Ø'}\n",
    "        \n",
    "#         page_str = str(page_number)\n",
    "#         nepali_page_num = ''.join(nepali_numerals.get(digit, digit) for digit in page_str)\n",
    "        \n",
    "#         return f\"\\n--- ‡§™‡•É‡§∑‡•ç‡§† {nepali_page_num} ---\\n\"\n",
    "    \n",
    "#     def __init__(self, max_pages_batch=5, dpi=200):\n",
    "#         \"\"\"\n",
    "#         Memory-optimized PDF text extractor\n",
    "        \n",
    "#         Args:\n",
    "#             max_pages_batch: Process this many pages at once (lower = less memory)\n",
    "#             dpi: Image resolution (lower = less memory, but worse OCR quality)\n",
    "#         \"\"\"\n",
    "#         self.max_pages_batch = max_pages_batch\n",
    "#         self.dpi = dpi\n",
    "        \n",
    "#     def extract_text_lightweight(self, pdf_path):\n",
    "#         \"\"\"Lightweight text extraction - tries pdfplumber first\"\"\"\n",
    "#         try:\n",
    "#             text = \"\"\n",
    "#             with pdfplumber.open(pdf_path) as pdf:\n",
    "#                 total_pages = len(pdf.pages)\n",
    "#                 print(f\"Processing {total_pages} pages...\")\n",
    "                \n",
    "#                 for page_num, page in enumerate(pdf.pages):\n",
    "#                     print(f\"\\r‡§™‡•É‡§∑‡•ç‡§† {page_num + 1}/{total_pages}\", end=\"\", flush=True)\n",
    "                    \n",
    "#                     page_text = page.extract_text()\n",
    "#                     if page_text:\n",
    "#                         # Clean the text to remove English and numbers\n",
    "#                         cleaned_text = self.clean_nepali_text(page_text)\n",
    "#                         if cleaned_text.strip():  # Only add if there's content after cleaning\n",
    "#                             text += self.format_page_separator(page_num + 1) + cleaned_text\n",
    "                    \n",
    "#                     # Clear memory every few pages\n",
    "#                     if (page_num + 1) % 10 == 0:\n",
    "#                         gc.collect()\n",
    "                \n",
    "#                 print()  # New line after progress\n",
    "#                 return text\n",
    "                \n",
    "#         except Exception as e:\n",
    "#             print(f\"Error with text extraction: {e}\")\n",
    "#             return None\n",
    "    \n",
    "#     def extract_with_batched_ocr(self, pdf_path, output_file=None, language='nep'):\n",
    "#         \"\"\"\n",
    "#         Memory-efficient OCR - processes pages in small batches\n",
    "#         Optionally saves directly to file to avoid keeping everything in memory\n",
    "#         \"\"\"\n",
    "#         try:\n",
    "#             # Get total page count first\n",
    "#             from pdf2image.exceptions import PDFInfoNotInstalledError\n",
    "            \n",
    "#             print(\"Analyzing PDF...\")\n",
    "#             total_pages = self._get_page_count(pdf_path)\n",
    "#             print(f\"Total pages: {total_pages}\")\n",
    "            \n",
    "#             # Open output file if specified\n",
    "#             output_handle = None\n",
    "#             if output_file:\n",
    "#                 output_handle = open(output_file, 'w', encoding='utf-8')\n",
    "#                 print(f\"‡§´‡§æ‡§á‡§≤‡§Æ‡§æ ‡§∏‡•á‡§≠ ‡§ó‡§∞‡•ç‡§¶‡•à: {output_file}\")\n",
    "            \n",
    "#             all_text = \"\"\n",
    "            \n",
    "#             # Process in batches\n",
    "#             for start_page in range(0, total_pages, self.max_pages_batch):\n",
    "#                 end_page = min(start_page + self.max_pages_batch, total_pages)\n",
    "#                 print(f\"\\n‡§™‡•É‡§∑‡•ç‡§† {start_page + 1}-{end_page} ‡§™‡•ç‡§∞‡§ï‡•ç‡§∞‡§ø‡§Ø‡§æ ‡§ó‡§∞‡•ç‡§¶‡•à...\")\n",
    "                \n",
    "#                 # Convert only current batch to images\n",
    "#                 images = convert_from_path(\n",
    "#                     pdf_path,\n",
    "#                     dpi=self.dpi,\n",
    "#                     first_page=start_page + 1,\n",
    "#                     last_page=end_page\n",
    "#                 )\n",
    "                \n",
    "#                 # Process each image in the batch\n",
    "#                 for i, image in enumerate(images):\n",
    "#                     current_page = start_page + i + 1\n",
    "#                     print(f\"  ‡§™‡•É‡§∑‡•ç‡§† {current_page} OCR...\")\n",
    "                    \n",
    "#                     # Extract text from current page\n",
    "#                     try:\n",
    "#                         page_text = pytesseract.image_to_string(\n",
    "#                             image, \n",
    "#                             lang=language,\n",
    "#                             config='--psm 6'\n",
    "#                         )\n",
    "                        \n",
    "#                         # Clean the extracted text\n",
    "#                         cleaned_text = self.clean_nepali_text(page_text)\n",
    "                        \n",
    "#                         if cleaned_text.strip():  # Only add if there's meaningful content\n",
    "#                             formatted_text = self.format_page_separator(current_page) + cleaned_text\n",
    "                            \n",
    "#                             if output_handle:\n",
    "#                                 # Write directly to file\n",
    "#                                 output_handle.write(formatted_text)\n",
    "#                                 output_handle.flush()\n",
    "#                             else:\n",
    "#                                 all_text += formatted_text\n",
    "                            \n",
    "#                     except Exception as e:\n",
    "#                         print(f\"‡§™‡•É‡§∑‡•ç‡§† {current_page} ‡§§‡•ç‡§∞‡•Å‡§ü‡§ø: {e}\")\n",
    "                    \n",
    "#                     # Clear individual image from memory\n",
    "#                     del image\n",
    "                \n",
    "#                 # Clear batch from memory\n",
    "#                 del images\n",
    "#                 gc.collect()\n",
    "                \n",
    "#                 print(f\"  ‡§™‡•Ç‡§∞‡•ç‡§£ ‡§≠‡§Ø‡•ã‡•§ ‡§Æ‡•á‡§Æ‡•ã‡§∞‡•Ä ‡§ñ‡§æ‡§≤‡•Ä ‡§ó‡§∞‡§ø‡§Ø‡•ã‡•§\")\n",
    "            \n",
    "#             # Close output file if used\n",
    "#             if output_handle:\n",
    "#                 output_handle.close()\n",
    "#                 print(f\"\\n‡§ü‡•á‡§ï‡•ç‡§∏‡•ç‡§ü ‡§∏‡•á‡§≠ ‡§≠‡§Ø‡•ã: {output_file}\")\n",
    "#                 return f\"‡§ü‡•á‡§ï‡•ç‡§∏‡•ç‡§ü ‡§∏‡•á‡§≠ ‡§≠‡§Ø‡•ã {output_file}\"\n",
    "#             else:\n",
    "#                 return all_text\n",
    "                \n",
    "#         except Exception as e:\n",
    "#             print(f\"Error with batched OCR: {e}\")\n",
    "#             if output_handle:\n",
    "#                 output_handle.close()\n",
    "#             return None\n",
    "    \n",
    "#     def _get_page_count(self, pdf_path):\n",
    "#         \"\"\"Get total page count without loading entire PDF\"\"\"\n",
    "#         try:\n",
    "#             with pdfplumber.open(pdf_path) as pdf:\n",
    "#                 return len(pdf.pages)\n",
    "#         except:\n",
    "#             # Fallback method\n",
    "#             try:\n",
    "#                 with open(pdf_path, 'rb') as file:\n",
    "#                     pdf_reader = PyPDF2.PdfReader(file)\n",
    "#                     return len(pdf_reader.pages)\n",
    "#             except:\n",
    "#                 return 1  # Assume 1 page if can't determine\n",
    "    \n",
    "#     def extract_single_page(self, pdf_path, page_number, language='nep'):\n",
    "#         \"\"\"Extract text from a single page (for testing)\"\"\"\n",
    "#         try:\n",
    "#             print(f\"‡§™‡•É‡§∑‡•ç‡§† {page_number} ‡§®‡§ø‡§ï‡§æ‡§≤‡•ç‡§¶‡•à...\")\n",
    "            \n",
    "#             # Convert single page to image\n",
    "#             images = convert_from_path(\n",
    "#                 pdf_path,\n",
    "#                 dpi=self.dpi,\n",
    "#                 first_page=page_number,\n",
    "#                 last_page=page_number\n",
    "#             )\n",
    "            \n",
    "#             if images:\n",
    "#                 image = images[0]\n",
    "#                 text = pytesseract.image_to_string(image, lang=language, config='--psm 6')\n",
    "                \n",
    "#                 # Clean the text\n",
    "#                 cleaned_text = self.clean_nepali_text(text)\n",
    "                \n",
    "#                 # Clean up\n",
    "#                 del images\n",
    "#                 del image\n",
    "#                 gc.collect()\n",
    "                \n",
    "#                 return cleaned_text\n",
    "            \n",
    "#         except Exception as e:\n",
    "#             print(f\"‡§è‡§â‡§ü‡•à ‡§™‡•É‡§∑‡•ç‡§† ‡§®‡§ø‡§ï‡§æ‡§≤‡•ç‡§® ‡§§‡•ç‡§∞‡•Å‡§ü‡§ø: {e}\")\n",
    "#             return None\n",
    "    \n",
    "#     def smart_extract(self, pdf_path, output_file=None, language='nep'):\n",
    "#         \"\"\"\n",
    "#         Smart extraction: tries text extraction first, falls back to OCR\n",
    "#         Saves directly to file to minimize memory usage\n",
    "#         \"\"\"\n",
    "#         print(\"=== ‡§®‡•á‡§™‡§æ‡§≤‡•Ä PDF ‡§ü‡•á‡§ï‡•ç‡§∏‡•ç‡§ü ‡§®‡§ø‡§ï‡§æ‡§≤‡•ç‡§®‡•á ===\")\n",
    "#         print(f\"‡§á‡§®‡§™‡•Å‡§ü: {pdf_path}\")\n",
    "        \n",
    "#         # First, try regular text extraction\n",
    "#         print(\"\\n‡•ß. ‡§∏‡§æ‡§Æ‡§æ‡§®‡•ç‡§Ø ‡§ü‡•á‡§ï‡•ç‡§∏‡•ç‡§ü ‡§®‡§ø‡§ï‡§æ‡§≤‡•ç‡§®‡•á ‡§™‡•ç‡§∞‡§Ø‡§æ‡§∏...\")\n",
    "#         text = self.extract_text_lightweight(pdf_path)\n",
    "        \n",
    "#         if text and self._contains_meaningful_text(text):\n",
    "#             print(\"‚úì ‡§∏‡§æ‡§Æ‡§æ‡§®‡•ç‡§Ø ‡§®‡§ø‡§ï‡§æ‡§∏‡•Ä‡§Æ‡§æ ‡§Ö‡§∞‡•ç‡§•‡§™‡•Ç‡§∞‡•ç‡§£ ‡§ü‡•á‡§ï‡•ç‡§∏‡•ç‡§ü ‡§≠‡•á‡§ü‡§ø‡§Ø‡•ã!\")\n",
    "            \n",
    "#             if output_file:\n",
    "#                 with open(output_file, 'w', encoding='utf-8') as f:\n",
    "#                     f.write(text)\n",
    "#                 print(f\"‚úì ‡§ü‡•á‡§ï‡•ç‡§∏‡•ç‡§ü ‡§∏‡•á‡§≠ ‡§≠‡§Ø‡•ã: {output_file}\")\n",
    "#                 return f\"‡§ü‡•á‡§ï‡•ç‡§∏‡•ç‡§ü ‡§∏‡•á‡§≠ ‡§≠‡§Ø‡•ã {output_file}\"\n",
    "#             else:\n",
    "#                 return text\n",
    "        \n",
    "#         # If regular extraction didn't work, use OCR\n",
    "#         print(\"\\n‡•®. ‡§∏‡§æ‡§Æ‡§æ‡§®‡•ç‡§Ø ‡§®‡§ø‡§ï‡§æ‡§∏‡•Ä ‡§∞‡§æ‡§Æ‡•ç‡§∞‡•ã ‡§≠‡§è‡§®‡•§ OCR ‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó ‡§ó‡§∞‡•ç‡§¶‡•à...\")\n",
    "#         return self.extract_with_batched_ocr(pdf_path, output_file, language)\n",
    "    \n",
    "#     def _contains_meaningful_text(self, text):\n",
    "#         \"\"\"Check if extracted text is meaningful\"\"\"\n",
    "#         if not text:\n",
    "#             return False\n",
    "        \n",
    "#         # Remove whitespace and count actual characters\n",
    "#         clean_text = ''.join(text.split())\n",
    "        \n",
    "#         # Check for minimum length and variety\n",
    "#         if len(clean_text) < 50:\n",
    "#             return False\n",
    "        \n",
    "#         # Check for Nepali characters (Devanagari)\n",
    "#         nepali_chars = sum(1 for char in clean_text if 0x0900 <= ord(char) <= 0x097F)\n",
    "        \n",
    "#         # If we have Nepali characters or substantial English text\n",
    "#         return nepali_chars > 10 or len(clean_text) > 200\n",
    "\n",
    "\n",
    "# class BatchPDFProcessor:\n",
    "#     \"\"\"\n",
    "#     Batch processor for multiple PDF files in a directory\n",
    "#     \"\"\"\n",
    "    \n",
    "#     def __init__(self, batch_size=3, dpi=200):\n",
    "#         self.extractor = MemoryOptimizedPDFExtractor(max_pages_batch=batch_size, dpi=dpi)\n",
    "#         self.processed_files = []\n",
    "#         self.failed_files = []\n",
    "    \n",
    "#     def find_pdf_files(self, folder_path):\n",
    "#         \"\"\"Find all PDF files in the given folder\"\"\"\n",
    "#         folder_path = Path(folder_path)\n",
    "        \n",
    "#         if not folder_path.exists():\n",
    "#             raise FileNotFoundError(f\"Folder not found: {folder_path}\")\n",
    "        \n",
    "#         if not folder_path.is_dir():\n",
    "#             raise NotADirectoryError(f\"Path is not a directory: {folder_path}\")\n",
    "        \n",
    "#         # Find all PDF files (case insensitive)\n",
    "#         pdf_files = []\n",
    "#         for ext in ['*.pdf', '*.PDF']:\n",
    "#             pdf_files.extend(folder_path.glob(ext))\n",
    "        \n",
    "#         return sorted(pdf_files)\n",
    "    \n",
    "#     def process_folder(self, input_folder, output_folder=None, skip_existing=True):\n",
    "#         \"\"\"\n",
    "#         Process all PDF files in a folder\n",
    "        \n",
    "#         Args:\n",
    "#             input_folder: Path to folder containing PDF files\n",
    "#             output_folder: Output folder (if None, creates 'extracted_text' in input folder)\n",
    "#             skip_existing: Skip files that already have output files\n",
    "#         \"\"\"\n",
    "#         input_path = Path(input_folder)\n",
    "        \n",
    "#         # Set up output folder\n",
    "#         if output_folder is None:\n",
    "#             output_path = input_path / \"extracted_text\"\n",
    "#         else:\n",
    "#             output_path = Path(output_folder)\n",
    "        \n",
    "#         # Create output folder if it doesn't exist\n",
    "#         output_path.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "#         # Find all PDF files\n",
    "#         pdf_files = self.find_pdf_files(input_folder)\n",
    "        \n",
    "#         if not pdf_files:\n",
    "#             print(f\"‡§ï‡•Å‡§®‡•à PDF ‡§´‡§æ‡§á‡§≤‡§π‡§∞‡•Ç ‡§≠‡•á‡§ü‡§ø‡§è‡§®‡§®‡•ç: {input_folder}\")\n",
    "#             return\n",
    "        \n",
    "#         print(f\"‡§≠‡•á‡§ü‡§ø‡§è‡§ï‡§æ PDF ‡§´‡§æ‡§á‡§≤‡§π‡§∞‡•Ç: {len(pdf_files)}\")\n",
    "#         print(\"=\" * 50)\n",
    "        \n",
    "#         # Process each PDF\n",
    "#         for i, pdf_file in enumerate(pdf_files, 1):\n",
    "#             print(f\"\\n[{i}/{len(pdf_files)}] ‡§™‡•ç‡§∞‡§ï‡•ç‡§∞‡§ø‡§Ø‡§æ ‡§ó‡§∞‡•ç‡§¶‡•à: {pdf_file.name}\")\n",
    "            \n",
    "#             # Generate output filename\n",
    "#             output_filename = pdf_file.stem + \"_extracted.txt\"\n",
    "#             output_file = output_path / output_filename\n",
    "            \n",
    "#             # Skip if output already exists and skip_existing is True\n",
    "#             if skip_existing and output_file.exists():\n",
    "#                 print(f\"‚è≠Ô∏è  ‡§∏‡•ç‡§ï‡§ø‡§™ ‡§ó‡§∞‡•ç‡§¶‡•à (‡§™‡§π‡§ø‡§≤‡•á ‡§®‡•à ‡§Ö‡§µ‡§∏‡•ç‡§•‡§ø‡§§): {output_filename}\")\n",
    "#                 continue\n",
    "            \n",
    "#             try:\n",
    "#                 # Process the PDF\n",
    "#                 start_time = time.time()\n",
    "#                 result = self.extractor.smart_extract(\n",
    "#                     str(pdf_file), \n",
    "#                     str(output_file), \n",
    "#                     language='nep'\n",
    "#                 )\n",
    "                \n",
    "#                 end_time = time.time()\n",
    "#                 duration = end_time - start_time\n",
    "                \n",
    "#                 if result:\n",
    "#                     print(f\"‚úÖ ‡§∏‡§´‡§≤: {pdf_file.name} ({duration:.1f} ‡§∏‡•á‡§ï‡•á‡§®‡•ç‡§°)\")\n",
    "#                     self.processed_files.append({\n",
    "#                         'input': str(pdf_file),\n",
    "#                         'output': str(output_file),\n",
    "#                         'duration': duration\n",
    "#                     })\n",
    "#                 else:\n",
    "#                     print(f\"‚ùå ‡§Ö‡§∏‡§´‡§≤: {pdf_file.name}\")\n",
    "#                     self.failed_files.append(str(pdf_file))\n",
    "                \n",
    "#             except Exception as e:\n",
    "#                 print(f\"‚ùå ‡§§‡•ç‡§∞‡•Å‡§ü‡§ø ‡§™‡•ç‡§∞‡§ï‡•ç‡§∞‡§ø‡§Ø‡§æ ‡§ó‡§∞‡•ç‡§¶‡§æ {pdf_file.name}: {e}\")\n",
    "#                 self.failed_files.append(str(pdf_file))\n",
    "            \n",
    "#             # Clean memory between files\n",
    "#             gc.collect()\n",
    "        \n",
    "#         # Print summary\n",
    "#         self.print_summary()\n",
    "    \n",
    "#     def print_summary(self):\n",
    "#         \"\"\"Print processing summary\"\"\"\n",
    "#         print(\"\\n\" + \"=\" * 50)\n",
    "#         print(\"‡§™‡•ç‡§∞‡§ï‡•ç‡§∞‡§ø‡§Ø‡§æ ‡§∏‡§æ‡§∞‡§æ‡§Ç‡§∂:\")\n",
    "#         print(f\"‚úÖ ‡§∏‡§´‡§≤ ‡§´‡§æ‡§á‡§≤‡§π‡§∞‡•Ç: {len(self.processed_files)}\")\n",
    "#         print(f\"‚ùå ‡§Ö‡§∏‡§´‡§≤ ‡§´‡§æ‡§á‡§≤‡§π‡§∞‡•Ç: {len(self.failed_files)}\")\n",
    "        \n",
    "#         if self.processed_files:\n",
    "#             total_time = sum(f['duration'] for f in self.processed_files)\n",
    "#             print(f\"‚è±Ô∏è  ‡§ï‡•Å‡§≤ ‡§∏‡§Æ‡§Ø: {total_time:.1f} ‡§∏‡•á‡§ï‡•á‡§®‡•ç‡§°\")\n",
    "#             print(f\"üìÅ ‡§Ü‡§â‡§ü‡§™‡•Å‡§ü ‡§´‡•ã‡§≤‡•ç‡§°‡§∞: {Path(self.processed_files[0]['output']).parent}\")\n",
    "        \n",
    "#         if self.failed_files:\n",
    "#             print(\"\\n‚ùå ‡§Ö‡§∏‡§´‡§≤ ‡§´‡§æ‡§á‡§≤‡§π‡§∞‡•Ç:\")\n",
    "#             for failed_file in self.failed_files:\n",
    "#                 print(f\"   - {Path(failed_file).name}\")\n",
    "\n",
    "\n",
    "# # Simple wrapper functions for easy use\n",
    "# def extract_nepali_pdf_memory_safe(pdf_path, output_file=None, batch_size=3, dpi=200):\n",
    "#     \"\"\"\n",
    "#     Memory-safe Nepali PDF extraction - removes all English text and numbers\n",
    "    \n",
    "#     Args:\n",
    "#         pdf_path: Path to PDF file\n",
    "#         output_file: Save to file instead of returning text (recommended for large PDFs)\n",
    "#         batch_size: Pages to process at once (lower = less memory)\n",
    "#         dpi: Image resolution (lower = less memory)\n",
    "#     \"\"\"\n",
    "#     extractor = MemoryOptimizedPDFExtractor(max_pages_batch=batch_size, dpi=dpi)\n",
    "#     return extractor.smart_extract(pdf_path, output_file, language='nep')\n",
    "\n",
    "\n",
    "# def process_pdf_folder(input_folder, output_folder=None, batch_size=3, dpi=200, skip_existing=True):\n",
    "#     \"\"\"\n",
    "#     Process all PDF files in a folder\n",
    "    \n",
    "#     Args:\n",
    "#         input_folder: Path to folder containing PDF files\n",
    "#         output_folder: Output folder (if None, creates 'extracted_text' in input folder)\n",
    "#         batch_size: Pages to process at once (lower = less memory)\n",
    "#         dpi: Image resolution (lower = less memory)\n",
    "#         skip_existing: Skip files that already have output files\n",
    "#     \"\"\"\n",
    "#     processor = BatchPDFProcessor(batch_size=batch_size, dpi=dpi)\n",
    "#     processor.process_folder(input_folder, output_folder, skip_existing)\n",
    "#     return processor\n",
    "\n",
    "\n",
    "# def test_single_page_clean(pdf_path, page_num=1):\n",
    "#     \"\"\"Test extraction on a single page first - only Nepali text\"\"\"\n",
    "#     extractor = MemoryOptimizedPDFExtractor(dpi=200)\n",
    "#     return extractor.extract_single_page(pdf_path, page_num, language='nep')\n",
    "\n",
    "\n",
    "# # Add these improved methods to your existing class\n",
    "\n",
    "# def test_ocr_setup(self):\n",
    "#     \"\"\"Test if Nepali OCR is working properly\"\"\"\n",
    "#     try:\n",
    "#         # Get available languages\n",
    "#         languages = pytesseract.get_languages()\n",
    "#         print(\"Available Tesseract languages:\")\n",
    "#         for lang in languages:\n",
    "#             print(f\"  - {lang}\")\n",
    "        \n",
    "#         if 'nep' in languages:\n",
    "#             print(\"‚úÖ Nepali (nep) language pack found!\")\n",
    "#             return True\n",
    "#         else:\n",
    "#             print(\"‚ùå Nepali language pack NOT found!\")\n",
    "#             print(\"Install with: sudo apt-get install tesseract-ocr-nep\")\n",
    "#             return False\n",
    "            \n",
    "#     except Exception as e:\n",
    "#         print(f\"Error checking OCR setup: {e}\")\n",
    "#         return False\n",
    "\n",
    "# def extract_with_multiple_methods(self, pdf_path, page_number=1):\n",
    "#     \"\"\"Try multiple OCR methods for better results\"\"\"\n",
    "#     try:\n",
    "#         print(f\"Testing multiple OCR methods on page {page_number}...\")\n",
    "        \n",
    "#         # Convert page to image\n",
    "#         images = convert_from_path(\n",
    "#             pdf_path,\n",
    "#             dpi=300,  # Higher DPI for better quality\n",
    "#             first_page=page_number,\n",
    "#             last_page=page_number\n",
    "#         )\n",
    "        \n",
    "#         if not images:\n",
    "#             return None\n",
    "        \n",
    "#         image = images[0]\n",
    "        \n",
    "#         # Method 1: Standard Nepali OCR\n",
    "#         print(\"Method 1: Standard Nepali OCR...\")\n",
    "#         try:\n",
    "#             text1 = pytesseract.image_to_string(image, lang='nep', config='--psm 6')\n",
    "#             print(f\"Result 1 (first 100 chars): {text1[:100]}\")\n",
    "#         except:\n",
    "#             text1 = \"\"\n",
    "        \n",
    "#         # Method 2: Hindi OCR (sometimes works better for Devanagari)\n",
    "#         print(\"Method 2: Hindi OCR...\")\n",
    "#         try:\n",
    "#             text2 = pytesseract.image_to_string(image, lang='hin', config='--psm 6')\n",
    "#             print(f\"Result 2 (first 100 chars): {text2[:100]}\")\n",
    "#         except:\n",
    "#             text2 = \"\"\n",
    "        \n",
    "#         # Method 3: Multiple languages\n",
    "#         print(\"Method 3: Multi-language OCR...\")\n",
    "#         try:\n",
    "#             text3 = pytesseract.image_to_string(image, lang='nep+hin+eng', config='--psm 6')\n",
    "#             print(f\"Result 3 (first 100 chars): {text3[:100]}\")\n",
    "#         except:\n",
    "#             text3 = \"\"\n",
    "        \n",
    "#         # Method 4: Different PSM mode\n",
    "#         print(\"Method 4: Different page segmentation...\")\n",
    "#         try:\n",
    "#             text4 = pytesseract.image_to_string(image, lang='nep', config='--psm 1')\n",
    "#             print(f\"Result 4 (first 100 chars): {text4[:100]}\")\n",
    "#         except:\n",
    "#             text4 = \"\"\n",
    "        \n",
    "#         # Clean up\n",
    "#         del images, image\n",
    "#         gc.collect()\n",
    "        \n",
    "#         return {\n",
    "#             'standard_nepali': text1,\n",
    "#             'hindi': text2,\n",
    "#             'multi_lang': text3,\n",
    "#             'different_psm': text4\n",
    "#         }\n",
    "        \n",
    "#     except Exception as e:\n",
    "#         print(f\"Error in multiple methods test: {e}\")\n",
    "#         return None\n",
    "\n",
    "# def preprocess_image_for_ocr(self, image):\n",
    "#     \"\"\"Preprocess image to improve OCR accuracy\"\"\"\n",
    "#     import cv2\n",
    "#     import numpy as np\n",
    "    \n",
    "#     try:\n",
    "#         # Convert PIL to OpenCV format\n",
    "#         opencv_image = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "#         # Convert to grayscale\n",
    "#         gray = cv2.cvtColor(opencv_image, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "#         # Apply denoising\n",
    "#         denoised = cv2.fastNlMeansDenoising(gray)\n",
    "        \n",
    "#         # Apply threshold to get better contrast\n",
    "#         _, thresh = cv2.threshold(denoised, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "        \n",
    "#         # Convert back to PIL format\n",
    "#         processed_image = Image.fromarray(thresh)\n",
    "        \n",
    "#         return processed_image\n",
    "        \n",
    "#     except ImportError:\n",
    "#         print(\"OpenCV not installed. Using original image.\")\n",
    "#         return image\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error preprocessing image: {e}\")\n",
    "#         return image\n",
    "\n",
    "# def extract_with_preprocessing(self, pdf_path, page_number=1):\n",
    "#     \"\"\"Extract text with image preprocessing\"\"\"\n",
    "#     try:\n",
    "#         print(f\"Extracting with preprocessing - Page {page_number}\")\n",
    "        \n",
    "#         # Convert to image\n",
    "#         images = convert_from_path(\n",
    "#             pdf_path,\n",
    "#             dpi=300,\n",
    "#             first_page=page_number,\n",
    "#             last_page=page_number\n",
    "#         )\n",
    "        \n",
    "#         if not images:\n",
    "#             return None\n",
    "        \n",
    "#         original_image = images[0]\n",
    "        \n",
    "#         # Preprocess image\n",
    "#         processed_image = self.preprocess_image_for_ocr(original_image)\n",
    "        \n",
    "#         # Try OCR on both original and processed\n",
    "#         print(\"Trying OCR on original image...\")\n",
    "#         text_original = pytesseract.image_to_string(original_image, lang='nep', config='--psm 6')\n",
    "        \n",
    "#         print(\"Trying OCR on processed image...\")\n",
    "#         text_processed = pytesseract.image_to_string(processed_image, lang='nep', config='--psm 6')\n",
    "        \n",
    "#         # Clean up\n",
    "#         del images, original_image, processed_image\n",
    "#         gc.collect()\n",
    "        \n",
    "#         print(f\"Original result (first 100): {text_original[:100]}\")\n",
    "#         print(f\"Processed result (first 100): {text_processed[:100]}\")\n",
    "        \n",
    "#         # Return the better result\n",
    "#         if len(text_processed.strip()) > len(text_original.strip()):\n",
    "#             return text_processed\n",
    "#         else:\n",
    "#             return text_original\n",
    "            \n",
    "#     except Exception as e:\n",
    "#         print(f\"Error with preprocessing: {e}\")\n",
    "#         return None\n",
    "\n",
    "# # Updated diagnostic function\n",
    "# def diagnose_pdf_issues(pdf_path, test_page=1):\n",
    "#     \"\"\"Comprehensive diagnosis of PDF extraction issues\"\"\"\n",
    "#     extractor = MemoryOptimizedPDFExtractor()\n",
    "    \n",
    "#     print(\"üîç PDF ‡§®‡§ø‡§¶‡§æ‡§® ‡§∂‡•Å‡§∞‡•Ç ‡§ó‡§∞‡•ç‡§¶‡•à...\")\n",
    "#     print(\"=\" * 50)\n",
    "    \n",
    "#     # Check if file exists\n",
    "#     if not os.path.exists(pdf_path):\n",
    "#         print(f\"‚ùå ‡§´‡§æ‡§á‡§≤ ‡§≠‡•á‡§ü‡§ø‡§è‡§®: {pdf_path}\")\n",
    "#         return\n",
    "    \n",
    "#     print(f\"üìÅ ‡§´‡§æ‡§á‡§≤: {pdf_path}\")\n",
    "#     print(f\"üìÑ ‡§™‡§∞‡•Ä‡§ï‡•ç‡§∑‡§£ ‡§™‡•É‡§∑‡•ç‡§†: {test_page}\")\n",
    "    \n",
    "#     # Test OCR setup\n",
    "#     print(\"\\n1. OCR ‡§∏‡•á‡§ü‡§Ö‡§™ ‡§ú‡§æ‡§Å‡§ö...\")\n",
    "#     ocr_ok = extractor.test_ocr_setup()\n",
    "    \n",
    "#     if not ocr_ok:\n",
    "#         print(\"‚ö†Ô∏è  Nepali OCR ‡§∏‡•á‡§ü‡§Ö‡§™ ‡§∏‡§Æ‡§∏‡•ç‡§Ø‡§æ ‡§õ!\")\n",
    "#         return\n",
    "    \n",
    "#     # Test regular text extraction\n",
    "#     print(\"\\n2. ‡§∏‡§æ‡§Æ‡§æ‡§®‡•ç‡§Ø ‡§ü‡•á‡§ï‡•ç‡§∏‡•ç‡§ü ‡§®‡§ø‡§ï‡§æ‡§∏‡•Ä...\")\n",
    "#     regular_text = extractor.extract_text_lightweight(pdf_path)\n",
    "#     if regular_text and len(regular_text.strip()) > 50:\n",
    "#         print(\"‚úÖ ‡§∏‡§æ‡§Æ‡§æ‡§®‡•ç‡§Ø ‡§®‡§ø‡§ï‡§æ‡§∏‡•Ä ‡§∏‡§´‡§≤!\")\n",
    "#         print(f\"‡§®‡§Æ‡•Ç‡§®‡§æ: {regular_text[:200]}...\")\n",
    "#         return\n",
    "#     else:\n",
    "#         print(\"‚ùå ‡§∏‡§æ‡§Æ‡§æ‡§®‡•ç‡§Ø ‡§®‡§ø‡§ï‡§æ‡§∏‡•Ä ‡§Ö‡§∏‡§´‡§≤‡•§ OCR ‡§Ü‡§µ‡§∂‡•ç‡§Ø‡§ï‡•§\")\n",
    "    \n",
    "#     # Test multiple OCR methods\n",
    "#     print(f\"\\n3. ‡§µ‡§ø‡§≠‡§ø‡§®‡•ç‡§® OCR ‡§µ‡§ø‡§ß‡§ø‡§π‡§∞‡•Ç (‡§™‡•É‡§∑‡•ç‡§† {test_page})...\")\n",
    "#     methods_result = extractor.extract_with_multiple_methods(pdf_path, test_page)\n",
    "    \n",
    "#     if methods_result:\n",
    "#         for method, result in methods_result.items():\n",
    "#             quality = \"‚úÖ ‡§∞‡§æ‡§Æ‡•ç‡§∞‡•ã\" if len(result.strip()) > 20 else \"‚ùå ‡§ñ‡§∞‡§æ‡§¨\"\n",
    "#             print(f\"{method}: {quality} ({len(result)} chars)\")\n",
    "    \n",
    "#     # Test with preprocessing\n",
    "#     print(f\"\\n4. ‡§á‡§Æ‡•á‡§ú ‡§™‡•ç‡§∞‡•ã‡§∏‡•á‡§∏‡§ø‡§Ç‡§ó ‡§∏‡§π‡§ø‡§§...\")\n",
    "#     preprocessed_result = extractor.extract_with_preprocessing(pdf_path, test_page)\n",
    "#     if preprocessed_result:\n",
    "#         quality = \"‚úÖ ‡§∞‡§æ‡§Æ‡•ç‡§∞‡•ã\" if len(preprocessed_result.strip()) > 20 else \"‚ùå ‡§ñ‡§∞‡§æ‡§¨\"\n",
    "#         print(f\"‡§™‡•ç‡§∞‡•ã‡§∏‡•á‡§∏‡§ø‡§Ç‡§ó ‡§™‡§∞‡§ø‡§£‡§æ‡§Æ: {quality}\")\n",
    "#         print(f\"‡§®‡§Æ‡•Ç‡§®‡§æ: {preprocessed_result[:200]}...\")\n",
    "    \n",
    "#     print(\"\\n\" + \"=\" * 50)\n",
    "#     print(\"‡§®‡§ø‡§¶‡§æ‡§® ‡§∏‡§Æ‡•ç‡§™‡§®‡•ç‡§®!\")\n",
    "\n",
    "# # # Test your specific file\n",
    "# # if __name__ == \"__main__\":\n",
    "# #     # Test your problematic PDF\n",
    "# #     PDF_PATH = 'Nepali Materials/‡§Ö‡§∞‡•ç‡§•‡§§‡§®‡•ç‡§§‡•ç‡§∞‡§Æ‡§æ ‡§ï‡•ã‡§∞‡•ã‡§®‡§æ ‡§ï‡§π‡§∞.pdf'\n",
    "    \n",
    "# #     # Run diagnosis\n",
    "# #     diagnose_pdf_issues(PDF_PATH, test_page=1)\n",
    "# # # Example usage\n",
    "# if __name__ == \"__main__\":\n",
    "#     # Configuration\n",
    "#     INPUT_FOLDER = 'Nepali Materials'  # Folder containing PDF files\n",
    "#     OUTPUT_FOLDER = 'Book'            # Output folder (optional)\n",
    "    \n",
    "#     # Method 1: Process entire folder\n",
    "#     print(\"üöÄ ‡§∏‡§¨‡•à PDF ‡§´‡§æ‡§á‡§≤‡§π‡§∞‡•Ç ‡§™‡•ç‡§∞‡§ï‡•ç‡§∞‡§ø‡§Ø‡§æ ‡§ó‡§∞‡•ç‡§¶‡•à...\")\n",
    "#     processor = process_pdf_folder(\n",
    "#         input_folder=INPUT_FOLDER,\n",
    "#         output_folder=OUTPUT_FOLDER,\n",
    "#         batch_size=2,        # Small batches for low memory\n",
    "#         dpi=200,            # Balance of quality and speed\n",
    "#         skip_existing=True   # Skip already processed files\n",
    "#     )\n",
    "    \n",
    "#     # Method 2: Process specific folder with custom settings\n",
    "#     # processor = BatchPDFProcessor(batch_size=1, dpi=150)  # Very low memory\n",
    "#     # processor.process_folder(INPUT_FOLDER, OUTPUT_FOLDER, skip_existing=True)\n",
    "    \n",
    "#     print(\"\\nüéâ ‡§∏‡§¨‡•à ‡§´‡§æ‡§á‡§≤‡§π‡§∞‡•Ç ‡§™‡•ç‡§∞‡§ï‡•ç‡§∞‡§ø‡§Ø‡§æ ‡§∏‡§Æ‡•ç‡§™‡§®‡•ç‡§®!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdcdf42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60c6c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "import pdfplumber\n",
    "import pytesseract\n",
    "from pdf2image import convert_from_path\n",
    "from PIL import Image, ImageEnhance, ImageFilter\n",
    "import os\n",
    "import gc\n",
    "import sys\n",
    "import re\n",
    "import time\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "class ScannedPDFExtractor:\n",
    "    def __init__(self, max_pages_batch=3, dpi=300):\n",
    "        \"\"\"\n",
    "        Optimized for scanned PDF documents\n",
    "        \n",
    "        Args:\n",
    "            max_pages_batch: Process this many pages at once (lower = less memory)\n",
    "            dpi: Image resolution (300+ recommended for scanned docs)\n",
    "        \"\"\"\n",
    "        self.max_pages_batch = max_pages_batch\n",
    "        self.dpi = dpi\n",
    "        \n",
    "    def clean_nepali_text(self, text):\n",
    "        \"\"\"Clean and filter text to keep only Nepali/Devanagari\"\"\"\n",
    "        if not text:\n",
    "            return \"\"\n",
    "        \n",
    "        cleaned_lines = []\n",
    "        for line in text.split('\\n'):\n",
    "            # Remove English letters, numbers, and excessive punctuation\n",
    "            cleaned_line = re.sub(r'[a-zA-Z0-9]', '', line)\n",
    "            cleaned_line = re.sub(r'[^\\u0900-\\u097F\\s‡•§‡••\\-\\,\\.\\?\\!\\:\\;]', '', cleaned_line)\n",
    "            cleaned_line = ' '.join(cleaned_line.split())\n",
    "            \n",
    "            if cleaned_line.strip() and len(cleaned_line.strip()) > 2:\n",
    "                cleaned_lines.append(cleaned_line)\n",
    "        \n",
    "        return '\\n'.join(cleaned_lines)\n",
    "    \n",
    "    def format_page_separator(self, page_number):\n",
    "        \"\"\"Create page separator in Nepali numerals\"\"\"\n",
    "        nepali_numerals = {'0': '‡•¶', '1': '‡•ß', '2': '‡•®', '3': '‡•©', '4': '‡•™', \n",
    "                          '5': '‡•´', '6': '‡•¨', '7': '‡•≠', '8': '‡•Æ', '9': '‡•Ø'}\n",
    "        \n",
    "        page_str = str(page_number)\n",
    "        nepali_page_num = ''.join(nepali_numerals.get(digit, digit) for digit in page_str)\n",
    "        return f\"\\n--- ‡§™‡•É‡§∑‡•ç‡§† {nepali_page_num} ---\\n\"\n",
    "    \n",
    "    def enhance_scanned_image(self, image):\n",
    "        \"\"\"\n",
    "        Enhance scanned image for better OCR results\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Convert PIL to OpenCV format\n",
    "            opencv_image = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)\n",
    "            \n",
    "            # Convert to grayscale\n",
    "            gray = cv2.cvtColor(opencv_image, cv2.COLOR_BGR2GRAY)\n",
    "            \n",
    "            # Apply denoising to remove scanning artifacts\n",
    "            denoised = cv2.fastNlMeansDenoising(gray, h=10, templateWindowSize=7, searchWindowSize=21)\n",
    "            \n",
    "            # Apply adaptive threshold for better text contrast\n",
    "            adaptive_thresh = cv2.adaptiveThreshold(\n",
    "                denoised, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2\n",
    "            )\n",
    "            \n",
    "            # Optional: Apply morphological operations to clean text\n",
    "            kernel = np.ones((1,1), np.uint8)\n",
    "            cleaned = cv2.morphologyEx(adaptive_thresh, cv2.MORPH_CLOSE, kernel)\n",
    "            \n",
    "            # Convert back to PIL\n",
    "            enhanced_image = Image.fromarray(cleaned)\n",
    "            \n",
    "            return enhanced_image\n",
    "            \n",
    "        except ImportError:\n",
    "            print(\"‚ö†Ô∏è  OpenCV not available. Using PIL enhancement...\")\n",
    "            return self.enhance_with_pil(image)\n",
    "        except Exception as e:\n",
    "            print(f\"Error enhancing image: {e}\")\n",
    "            return self.enhance_with_pil(image)\n",
    "    \n",
    "    def enhance_with_pil(self, image):\n",
    "        \"\"\"Fallback image enhancement using PIL only\"\"\"\n",
    "        try:\n",
    "            # Convert to grayscale\n",
    "            if image.mode != 'L':\n",
    "                image = image.convert('L')\n",
    "            \n",
    "            # Enhance contrast\n",
    "            enhancer = ImageEnhance.Contrast(image)\n",
    "            image = enhancer.enhance(2.0)\n",
    "            \n",
    "            # Enhance sharpness\n",
    "            enhancer = ImageEnhance.Sharpness(image)\n",
    "            image = enhancer.enhance(2.0)\n",
    "            \n",
    "            # Apply a slight blur to reduce noise, then sharpen\n",
    "            image = image.filter(ImageFilter.MedianFilter(size=3))\n",
    "            \n",
    "            return image\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"PIL enhancement error: {e}\")\n",
    "            return image\n",
    "    \n",
    "    def extract_text_from_scanned_page(self, image, page_num, language='nep'):\n",
    "        \"\"\"\n",
    "        Extract text from a single scanned page image with multiple methods\n",
    "        \"\"\"\n",
    "        results = {}\n",
    "        \n",
    "        # Method 1: Original image with different PSM modes\n",
    "        psm_modes = [6, 1, 3, 4, 8]  # Different page segmentation modes\n",
    "        \n",
    "        for psm in psm_modes:\n",
    "            try:\n",
    "                config = f'--psm {psm} -c tessedit_char_whitelist=‡§Ö‡§Ü‡§á‡§à‡§â‡§ä‡§è‡§ê‡§ì‡§î‡§ï‡§ñ‡§ó‡§ò‡§ô‡§ö‡§õ‡§ú‡§ù‡§û‡§ü‡§†‡§°‡§¢‡§£‡§§‡§•‡§¶‡§ß‡§®‡§™‡§´‡§¨‡§≠‡§Æ‡§Ø‡§∞‡§≤‡§µ‡§∂‡§∑‡§∏‡§π‡•§‡••‡§æ‡§ø‡•Ä‡•Å‡•Ç‡•á‡•à‡•ã‡•å‡§Ç‡§É‡•ç‡•¶‡•ß‡•®‡•©‡•™‡•´‡•¨‡•≠‡•Æ‡•Ø '\n",
    "                text = pytesseract.image_to_string(image, lang=language, config=config)\n",
    "                results[f'psm_{psm}'] = text\n",
    "            except Exception as e:\n",
    "                print(f\"PSM {psm} failed: {e}\")\n",
    "                results[f'psm_{psm}'] = \"\"\n",
    "        \n",
    "        # Method 2: Enhanced image\n",
    "        try:\n",
    "            enhanced_image = self.enhance_scanned_image(image)\n",
    "            config = '--psm 6 -c tessedit_char_whitelist=‡§Ö‡§Ü‡§á‡§à‡§â‡§ä‡§è‡§ê‡§ì‡§î‡§ï‡§ñ‡§ó‡§ò‡§ô‡§ö‡§õ‡§ú‡§ù‡§û‡§ü‡§†‡§°‡§¢‡§£‡§§‡§•‡§¶‡§ß‡§®‡§™‡§´‡§¨‡§≠‡§Æ‡§Ø‡§∞‡§≤‡§µ‡§∂‡§∑‡§∏‡§π‡•§‡••‡§æ‡§ø‡•Ä‡•Å‡•Ç‡•á‡•à‡•ã‡•å‡§Ç‡§É‡•ç‡•¶‡•ß‡•®‡•©‡•™‡•´‡•¨‡•≠‡•Æ‡•Ø '\n",
    "            enhanced_text = pytesseract.image_to_string(enhanced_image, lang=language, config=config)\n",
    "            results['enhanced'] = enhanced_text\n",
    "        except Exception as e:\n",
    "            print(f\"Enhanced extraction failed: {e}\")\n",
    "            results['enhanced'] = \"\"\n",
    "        \n",
    "        # Method 3: Try different languages\n",
    "        for lang in ['nep', 'hin', 'san']:\n",
    "            try:\n",
    "                text = pytesseract.image_to_string(image, lang=lang, config='--psm 6')\n",
    "                results[f'lang_{lang}'] = text\n",
    "            except:\n",
    "                results[f'lang_{lang}'] = \"\"\n",
    "        \n",
    "        # Find the best result\n",
    "        best_result = \"\"\n",
    "        best_score = 0\n",
    "        \n",
    "        for method, text in results.items():\n",
    "            if text:\n",
    "                # Score based on Devanagari character count and length\n",
    "                devanagari_chars = sum(1 for char in text if 0x0900 <= ord(char) <= 0x097F)\n",
    "                score = devanagari_chars * 2 + len(text.strip())\n",
    "                \n",
    "                if score > best_score:\n",
    "                    best_score = score\n",
    "                    best_result = text\n",
    "                    print(f\"  üìä Best method so far: {method} (score: {score})\")\n",
    "        \n",
    "        return best_result\n",
    "    \n",
    "    def extract_scanned_pdf(self, pdf_path, output_file=None, language='nep'):\n",
    "        \"\"\"\n",
    "        Extract text from scanned PDF with optimized settings\n",
    "        \"\"\"\n",
    "        try:\n",
    "            print(\"=== ‡§∏‡•ç‡§ï‡•ç‡§Ø‡§æ‡§® ‡§≠‡§è‡§ï‡•ã PDF ‡§ü‡•á‡§ï‡•ç‡§∏‡•ç‡§ü ‡§®‡§ø‡§ï‡§æ‡§≤‡•ç‡§®‡•á ===\")\n",
    "            print(f\"‡§´‡§æ‡§á‡§≤: {pdf_path}\")\n",
    "            print(f\"DPI: {self.dpi} (‡§â‡§ö‡•ç‡§ö ‡§ó‡•Å‡§£‡§∏‡•ç‡§§‡§∞)\")\n",
    "            \n",
    "            # Get total pages\n",
    "            total_pages = self._get_page_count(pdf_path)\n",
    "            print(f\"‡§ï‡•Å‡§≤ ‡§™‡•É‡§∑‡•ç‡§†‡§π‡§∞‡•Ç: {total_pages}\")\n",
    "            \n",
    "            # Setup output\n",
    "            output_handle = None\n",
    "            if output_file:\n",
    "                output_handle = open(output_file, 'w', encoding='utf-8')\n",
    "                print(f\"‡§Ü‡§â‡§ü‡§™‡•Å‡§ü ‡§´‡§æ‡§á‡§≤: {output_file}\")\n",
    "            \n",
    "            all_text = \"\"\n",
    "            \n",
    "            # Process in batches\n",
    "            for start_page in range(0, total_pages, self.max_pages_batch):\n",
    "                end_page = min(start_page + self.max_pages_batch, total_pages)\n",
    "                print(f\"\\nüìÑ ‡§™‡•É‡§∑‡•ç‡§† {start_page + 1}-{end_page} ‡§™‡•ç‡§∞‡§ï‡•ç‡§∞‡§ø‡§Ø‡§æ ‡§ó‡§∞‡•ç‡§¶‡•à...\")\n",
    "                \n",
    "                # Convert batch to high-resolution images\n",
    "                try:\n",
    "                    images = convert_from_path(\n",
    "                        pdf_path,\n",
    "                        dpi=self.dpi,\n",
    "                        first_page=start_page + 1,\n",
    "                        last_page=end_page,\n",
    "                        fmt='PNG'  # Better quality for scanned docs\n",
    "                    )\n",
    "                except Exception as e:\n",
    "                    print(f\"PDF to image conversion failed: {e}\")\n",
    "                    continue\n",
    "                \n",
    "                # Process each image\n",
    "                for i, image in enumerate(images):\n",
    "                    current_page = start_page + i + 1\n",
    "                    print(f\"  üîç ‡§™‡•É‡§∑‡•ç‡§† {current_page} OCR ‡§ó‡§∞‡•ç‡§¶‡•à...\")\n",
    "                    \n",
    "                    try:\n",
    "                        # Extract text with multiple methods\n",
    "                        start_time = time.time()\n",
    "                        page_text = self.extract_text_from_scanned_page(image, current_page, language)\n",
    "                        end_time = time.time()\n",
    "                        \n",
    "                        if page_text:\n",
    "                            # Clean the text\n",
    "                            cleaned_text = self.clean_nepali_text(page_text)\n",
    "                            \n",
    "                            if cleaned_text.strip():\n",
    "                                formatted_text = self.format_page_separator(current_page) + cleaned_text\n",
    "                                \n",
    "                                if output_handle:\n",
    "                                    output_handle.write(formatted_text)\n",
    "                                    output_handle.flush()\n",
    "                                else:\n",
    "                                    all_text += formatted_text\n",
    "                                \n",
    "                                print(f\"    ‚úÖ ‡§∏‡§´‡§≤ ({end_time-start_time:.1f}s, {len(cleaned_text)} chars)\")\n",
    "                            else:\n",
    "                                print(f\"    ‚ö†Ô∏è  ‡§∏‡§´‡§æ‡§à ‡§™‡§õ‡§ø ‡§ï‡•Å‡§®‡•à ‡§ü‡•á‡§ï‡•ç‡§∏‡•ç‡§ü ‡§¨‡§æ‡§Å‡§ï‡•Ä ‡§õ‡•à‡§®\")\n",
    "                        else:\n",
    "                            print(f\"    ‚ùå ‡§ï‡•Å‡§®‡•à ‡§ü‡•á‡§ï‡•ç‡§∏‡•ç‡§ü ‡§≠‡•á‡§ü‡§ø‡§è‡§®\")\n",
    "                            \n",
    "                    except Exception as e:\n",
    "                        print(f\"    ‚ùå ‡§§‡•ç‡§∞‡•Å‡§ü‡§ø: {e}\")\n",
    "                    \n",
    "                    # Clear memory\n",
    "                    del image\n",
    "                \n",
    "                # Clear batch\n",
    "                del images\n",
    "                gc.collect()\n",
    "                print(f\"  üßπ ‡§Æ‡•á‡§Æ‡•ã‡§∞‡•Ä ‡§∏‡§´‡§æ ‡§ó‡§∞‡§ø‡§Ø‡•ã\")\n",
    "            \n",
    "            # Close output file\n",
    "            if output_handle:\n",
    "                output_handle.close()\n",
    "                print(f\"\\n‚úÖ ‡§ü‡•á‡§ï‡•ç‡§∏‡•ç‡§ü ‡§∏‡•á‡§≠ ‡§≠‡§Ø‡•ã: {output_file}\")\n",
    "                return f\"‡§ü‡•á‡§ï‡•ç‡§∏‡•ç‡§ü ‡§∏‡•á‡§≠ ‡§≠‡§Ø‡•ã {output_file}\"\n",
    "            else:\n",
    "                return all_text\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"‡§Æ‡•Å‡§ñ‡•ç‡§Ø ‡§§‡•ç‡§∞‡•Å‡§ü‡§ø: {e}\")\n",
    "            if output_handle:\n",
    "                output_handle.close()\n",
    "            return None\n",
    "    \n",
    "    def _get_page_count(self, pdf_path):\n",
    "        \"\"\"Get total page count\"\"\"\n",
    "        try:\n",
    "            with pdfplumber.open(pdf_path) as pdf:\n",
    "                return len(pdf.pages)\n",
    "        except:\n",
    "            try:\n",
    "                with open(pdf_path, 'rb') as file:\n",
    "                    pdf_reader = PyPDF2.PdfReader(file)\n",
    "                    return len(pdf_reader.pages)\n",
    "            except:\n",
    "                return 1\n",
    "    \n",
    "    def test_single_scanned_page(self, pdf_path, page_number=1):\n",
    "        \"\"\"Test extraction on a single scanned page\"\"\"\n",
    "        try:\n",
    "            print(f\"üß™ ‡§™‡•É‡§∑‡•ç‡§† {page_number} ‡§™‡§∞‡•Ä‡§ï‡•ç‡§∑‡§£...\")\n",
    "            \n",
    "            # Convert single page to high-res image\n",
    "            images = convert_from_path(\n",
    "                pdf_path,\n",
    "                dpi=self.dpi,\n",
    "                first_page=page_number,\n",
    "                last_page=page_number,\n",
    "                fmt='PNG'\n",
    "            )\n",
    "            \n",
    "            if images:\n",
    "                image = images[0]\n",
    "                print(f\"üìè ‡§á‡§Æ‡•á‡§ú ‡§∏‡§æ‡§á‡§ú: {image.size}\")\n",
    "                \n",
    "                # Extract text\n",
    "                text = self.extract_text_from_scanned_page(image, page_number)\n",
    "                cleaned = self.clean_nepali_text(text)\n",
    "                \n",
    "                # Cleanup\n",
    "                del images, image\n",
    "                gc.collect()\n",
    "                \n",
    "                print(f\"‚úÖ ‡§™‡§∞‡•Ä‡§ï‡•ç‡§∑‡§£ ‡§∏‡§Æ‡•ç‡§™‡§®‡•ç‡§®!\")\n",
    "                print(f\"üìä ‡§ï‡§ö‡•ç‡§ö‡§æ ‡§ü‡•á‡§ï‡•ç‡§∏‡•ç‡§ü: {len(text)} chars\")\n",
    "                print(f\"üìä ‡§∏‡§´‡§æ ‡§ü‡•á‡§ï‡•ç‡§∏‡•ç‡§ü: {len(cleaned)} chars\")\n",
    "                print(f\"üî§ ‡§®‡§Æ‡•Ç‡§®‡§æ:\\n{cleaned[:300]}...\")\n",
    "                \n",
    "                return cleaned\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‡§™‡§∞‡•Ä‡§ï‡•ç‡§∑‡§£ ‡§§‡•ç‡§∞‡•Å‡§ü‡§ø: {e}\")\n",
    "            return None\n",
    "\n",
    "\n",
    "class BatchScannedPDFProcessor:\n",
    "    \"\"\"Process multiple scanned PDFs\"\"\"\n",
    "    \n",
    "    def __init__(self, batch_size=2, dpi=300):\n",
    "        self.extractor = ScannedPDFExtractor(max_pages_batch=batch_size, dpi=dpi)\n",
    "        self.processed_files = []\n",
    "        self.failed_files = []\n",
    "    \n",
    "    def process_scanned_folder(self, input_folder, output_folder=None, skip_existing=True):\n",
    "        \"\"\"Process all scanned PDFs in folder\"\"\"\n",
    "        input_path = Path(input_folder)\n",
    "        \n",
    "        if output_folder is None:\n",
    "            output_path = input_path / \"extracted_scanned_text\"\n",
    "        else:\n",
    "            output_path = Path(output_folder)\n",
    "        \n",
    "        output_path.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Find PDFs\n",
    "        pdf_files = []\n",
    "        for ext in ['*.pdf', '*.PDF']:\n",
    "            pdf_files.extend(input_path.glob(ext))\n",
    "        \n",
    "        if not pdf_files:\n",
    "            print(f\"‡§ï‡•Å‡§®‡•à PDF ‡§´‡§æ‡§á‡§≤ ‡§≠‡•á‡§ü‡§ø‡§è‡§®: {input_folder}\")\n",
    "            return\n",
    "        \n",
    "        print(f\"üîç ‡§≠‡•á‡§ü‡§ø‡§è‡§ï‡§æ ‡§∏‡•ç‡§ï‡•ç‡§Ø‡§æ‡§® PDF ‡§π‡§∞‡•Ç: {len(pdf_files)}\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        for i, pdf_file in enumerate(pdf_files, 1):\n",
    "            print(f\"\\n[{i}/{len(pdf_files)}] ‡§™‡•ç‡§∞‡§ï‡•ç‡§∞‡§ø‡§Ø‡§æ: {pdf_file.name}\")\n",
    "            \n",
    "            output_filename = pdf_file.stem + \"_scanned_extracted.txt\"\n",
    "            output_file = output_path / output_filename\n",
    "            \n",
    "            if skip_existing and output_file.exists():\n",
    "                print(f\"‚è≠Ô∏è  ‡§∏‡•ç‡§ï‡§ø‡§™ (‡§™‡§π‡§ø‡§≤‡•á ‡§¶‡•á‡§ñ‡§ø ‡§®‡•à ‡§õ): {output_filename}\")\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                start_time = time.time()\n",
    "                result = self.extractor.extract_scanned_pdf(\n",
    "                    str(pdf_file), \n",
    "                    str(output_file)\n",
    "                )\n",
    "                end_time = time.time()\n",
    "                \n",
    "                if result:\n",
    "                    duration = end_time - start_time\n",
    "                    print(f\"‚úÖ ‡§∏‡§´‡§≤: {pdf_file.name} ({duration:.1f}s)\")\n",
    "                    self.processed_files.append({\n",
    "                        'input': str(pdf_file),\n",
    "                        'output': str(output_file),\n",
    "                        'duration': duration\n",
    "                    })\n",
    "                else:\n",
    "                    print(f\"‚ùå ‡§Ö‡§∏‡§´‡§≤: {pdf_file.name}\")\n",
    "                    self.failed_files.append(str(pdf_file))\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå ‡§§‡•ç‡§∞‡•Å‡§ü‡§ø {pdf_file.name}: {e}\")\n",
    "                self.failed_files.append(str(pdf_file))\n",
    "            \n",
    "            gc.collect()\n",
    "        \n",
    "        self.print_summary()\n",
    "    \n",
    "    def print_summary(self):\n",
    "        \"\"\"Print processing summary\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"‡§∏‡•ç‡§ï‡•ç‡§Ø‡§æ‡§® PDF ‡§™‡•ç‡§∞‡§ï‡•ç‡§∞‡§ø‡§Ø‡§æ ‡§∏‡§æ‡§∞‡§æ‡§Ç‡§∂:\")\n",
    "        print(f\"‚úÖ ‡§∏‡§´‡§≤: {len(self.processed_files)}\")\n",
    "        print(f\"‚ùå ‡§Ö‡§∏‡§´‡§≤: {len(self.failed_files)}\")\n",
    "        \n",
    "        if self.processed_files:\n",
    "            total_time = sum(f['duration'] for f in self.processed_files)\n",
    "            print(f\"‚è±Ô∏è  ‡§ï‡•Å‡§≤ ‡§∏‡§Æ‡§Ø: {total_time:.1f} ‡§∏‡•á‡§ï‡•á‡§®‡•ç‡§°\")\n",
    "            avg_time = total_time / len(self.processed_files)\n",
    "            print(f\"üìä ‡§î‡§∏‡§§ ‡§∏‡§Æ‡§Ø ‡§™‡•ç‡§∞‡§§‡§ø ‡§´‡§æ‡§á‡§≤: {avg_time:.1f} ‡§∏‡•á‡§ï‡•á‡§®‡•ç‡§°\")\n",
    "\n",
    "\n",
    "# Simple functions for easy use\n",
    "def extract_scanned_pdf(pdf_path, output_file=None, dpi=300, batch_size=2):\n",
    "    \"\"\"Extract text from scanned PDF\"\"\"\n",
    "    extractor = ScannedPDFExtractor(max_pages_batch=batch_size, dpi=dpi)\n",
    "    return extractor.extract_scanned_pdf(pdf_path, output_file)\n",
    "\n",
    "def test_scanned_page(pdf_path, page_num=1, dpi=300):\n",
    "    \"\"\"Test single page extraction\"\"\"\n",
    "    extractor = ScannedPDFExtractor(dpi=dpi)\n",
    "    return extractor.test_single_scanned_page(pdf_path, page_num)\n",
    "\n",
    "def process_scanned_folder(input_folder, output_folder=None, dpi=300, batch_size=2):\n",
    "    \"\"\"Process all scanned PDFs in folder\"\"\"\n",
    "    processor = BatchScannedPDFProcessor(batch_size=batch_size, dpi=dpi)\n",
    "    processor.process_scanned_folder(input_folder, output_folder)\n",
    "    return processor\n",
    "\n",
    "\n",
    "# Usage example\n",
    "if __name__ == \"__main__\":\n",
    "    # Configuration for scanned PDFs\n",
    "    INPUT_FOLDER = '/var/home/ramrshrcg/Downloads/nepali books/milena'\n",
    "    OUTPUT_FOLDER = 'Books_Scanned'\n",
    "    \n",
    "    # Test single page first\n",
    "    print(\"üß™ ‡§™‡§π‡§ø‡§≤‡•á ‡§è‡§ï ‡§™‡•É‡§∑‡•ç‡§† ‡§™‡§∞‡•Ä‡§ï‡•ç‡§∑‡§£...\")\n",
    "    test_pdf = 'Nepali Materials/‡§Ö‡§∞‡•ç‡§•‡§§‡§®‡•ç‡§§‡•ç‡§∞‡§Æ‡§æ ‡§ï‡•ã‡§∞‡•ã‡§®‡§æ ‡§ï‡§π‡§∞.pdf'\n",
    "    \n",
    "    if os.path.exists(test_pdf):\n",
    "        result = test_scanned_page(test_pdf, page_num=1, dpi=700)\n",
    "        \n",
    "        if result and len(result.strip()) > 20:\n",
    "            print(\"‚úÖ ‡§™‡§∞‡•Ä‡§ï‡•ç‡§∑‡§£ ‡§∏‡§´‡§≤! ‡§™‡•Ç‡§∞‡•ç‡§£ ‡§™‡•ç‡§∞‡§ï‡•ç‡§∞‡§ø‡§Ø‡§æ ‡§∏‡•Å‡§∞‡•Å ‡§ó‡§∞‡•ç‡§¶‡•à...\")\n",
    "            \n",
    "            # Process all scanned PDFs\n",
    "            processor = process_scanned_folder(\n",
    "                INPUT_FOLDER, \n",
    "                OUTPUT_FOLDER, \n",
    "                dpi=700,        # High resolution for scanned docs\n",
    "                batch_size=1    # Very small batches for memory\n",
    "            )\n",
    "        else:\n",
    "            print(\"‚ùå ‡§™‡§∞‡•Ä‡§ï‡•ç‡§∑‡§£ ‡§Ö‡§∏‡§´‡§≤‡•§ ‡§ï‡•É‡§™‡§Ø‡§æ ‡§∏‡§Æ‡§∏‡•ç‡§Ø‡§æ ‡§ú‡§æ‡§Å‡§ö ‡§ó‡§∞‡•ç‡§®‡•Å‡§π‡•ã‡§∏‡•ç‡•§\")\n",
    "    else:\n",
    "        print(f\"‚ùå ‡§´‡§æ‡§á‡§≤ ‡§≠‡•á‡§ü‡§ø‡§è‡§®: {test_pdf}\")\n",
    "        print(\"‡§ï‡•É‡§™‡§Ø‡§æ PDF_PATH ‡§Ö‡§™‡§°‡•á‡§ü ‡§ó‡§∞‡•ç‡§®‡•Å‡§π‡•ã‡§∏‡•ç\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
